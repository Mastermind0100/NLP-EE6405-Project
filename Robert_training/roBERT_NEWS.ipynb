{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU_7aFidiYnf"
      },
      "source": [
        "## Before Start\n",
        "\n",
        "An initial data exploration was done to first gain some insights. The classes look balanced in the train data at about 50% each, and most reviews are of length 100-200. Even after removing stopwords, the most common word (br) is still a stopword since it is just a break in the text, and does not have any meaning. It should be added to the dictionary to be removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u8Op3ZBJk4KK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A little less than a decade ago, hockey fans w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The writers of the HBO series The Sopranos too...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Despite claims from the TV news outlet to offe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>After receiving 'subpar' service and experienc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   labels                                               text\n",
              "0       1  A little less than a decade ago, hockey fans w...\n",
              "1       1  The writers of the HBO series The Sopranos too...\n",
              "2       1  Despite claims from the TV news outlet to offe...\n",
              "3       1  After receiving 'subpar' service and experienc...\n",
              "4       1  After watching his beloved Seattle Mariners pr..."
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv('C:/Users/DELL/Downloads/news_fulltrain.csv', header=None)\n",
        "train_data.columns=['labels','text']\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "s055gGpWTGYv",
        "outputId": "28a4ddd6-9d23-4a2c-d75b-466e706a51b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import resample\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "train_data = pd.read_csv('C:/Users/DELL/Downloads/news_fulltrain.csv', header=None)\n",
        "train_data.columns=['labels','text']\n",
        "train_data = train_data[(train_data['labels'] == 1) | (train_data['labels'] == 4)]\n",
        "train_data['labels'].unique()\n",
        "\n",
        "train_data_satire  =train_data[train_data['labels'] == 1]\n",
        "train_data_reliable  =train_data[train_data['labels'] == 4]\n",
        "\n",
        "train_data_satire_sampled = resample(train_data_satire,\n",
        "                                     replace=True,\n",
        "                                     n_samples=len(train_data_satire),\n",
        "                                     random_state=42)\n",
        "\n",
        "train_data_balanced = pd.concat([train_data_satire_sampled, train_data_reliable])\n",
        "train_data_balanced['labels'] = train_data_balanced['labels'].replace({1:0, 4:1})\n",
        "\n",
        "\n",
        "test_data = pd.read_csv('C:/Users/DELL/Downloads/news_balancedtest.csv')\n",
        "\n",
        "test_data.columns = ['labels', 'text']\n",
        "test_data = test_data[(test_data['labels'] == 1) | (test_data['labels'] == 4)]\n",
        "\n",
        "test_data_balanced = test_data.copy()\n",
        "test_data_balanced['labels'] = test_data_balanced['labels'].replace({1: 0, 4: 1})\n",
        "test_data_balanced.head()\n",
        "train_data_balanced.head()\n",
        "train_data_balanced = train_data_balanced.reset_index(drop=True)\n",
        "test_data_balanced = test_data_balanced.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map: 100%|██████████| 24042/24042 [00:05<00:00, 4427.01 examples/s]\n",
            "Map: 100%|██████████| 1499/1499 [00:00<00:00, 3485.60 examples/s]\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import Dataset, load_metric\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    AutoConfig,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "def tokenize(data):\n",
        "    tokenized_data = tokenizer(data[\"text\"],\n",
        "                     padding = \"max_length\",\n",
        "                     truncation = True,\n",
        "                     max_length=128,\n",
        "                     return_tensors='pt')\n",
        "    tokenized_data['labels'] = torch.tensor(data[\"labels\"])\n",
        "    return tokenized_data\n",
        "# tokenized_train = train_data_balanced.map(tokenize, batched=True)\n",
        "# tokenized_test = test_data_balanced.map(tokenize, batched=True)\n",
        "config = AutoConfig.from_pretrained(\"roberta-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels = 2)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_data_balanced)\n",
        "test_dataset = Dataset.from_pandas(test_data_balanced)\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize, batched=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./result\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,                     \n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    f1 = load_metric(\"f1\")\n",
        "    precision = load_metric(\"precision\")\n",
        "    recall = load_metric(\"recall\")\n",
        "    accuracy = load_metric(\"accuracy\")\n",
        "\n",
        "    f1_score = f1.compute(predictions=predictions, references=labels, average='binary')\n",
        "    precision_score = precision.compute(predictions=predictions, references=labels, average='binary')\n",
        "    recall_score = recall.compute(predictions=predictions, references=labels, average='binary')\n",
        "    accuracy_score = accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score['accuracy'],\n",
        "        \"f1\": f1_score['f1'],}\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 500/9018 [11:30<3:12:15,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2595, 'grad_norm': 137.7894287109375, 'learning_rate': 4.722776668884454e-05, 'epoch': 0.17}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 1000/9018 [22:57<3:05:15,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1989, 'grad_norm': 0.34119951725006104, 'learning_rate': 4.445553337768907e-05, 'epoch': 0.33}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 1500/9018 [34:37<2:56:03,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2107, 'grad_norm': 0.31288692355155945, 'learning_rate': 4.1683300066533606e-05, 'epoch': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 2000/9018 [46:38<2:45:48,  1.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1702, 'grad_norm': 0.25357362627983093, 'learning_rate': 3.8911066755378136e-05, 'epoch': 0.67}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 2500/9018 [1:00:33<4:11:50,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1653, 'grad_norm': 0.0862274318933487, 'learning_rate': 3.613883344422267e-05, 'epoch': 0.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 3000/9018 [1:20:05<3:51:52,  2.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1432, 'grad_norm': 0.12171628326177597, 'learning_rate': 3.33666001330672e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 3006/9018 [1:20:19<3:27:47,  2.07s/it]C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_28884\\2321989148.py:43: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  f1 = load_metric(\"f1\")\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/precision/precision.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/recall/recall.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "                                                       \n",
            " 33%|███▎      | 3006/9018 [1:22:19<3:27:47,  2.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.46284037828445435, 'eval_accuracy': 0.8965977318212142, 'eval_f1': 0.9057750759878419, 'eval_runtime': 119.5348, 'eval_samples_per_second': 12.54, 'eval_steps_per_second': 1.573, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 3500/9018 [1:41:32<3:33:19,  2.32s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1179, 'grad_norm': 0.1208294928073883, 'learning_rate': 3.059436682191173e-05, 'epoch': 1.16}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 4000/9018 [2:01:06<3:17:04,  2.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1266, 'grad_norm': 0.08157272636890411, 'learning_rate': 2.7822133510756266e-05, 'epoch': 1.33}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 4500/9018 [2:20:29<2:55:50,  2.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0612, 'grad_norm': 0.03743109852075577, 'learning_rate': 2.5049900199600802e-05, 'epoch': 1.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 5000/9018 [2:40:12<2:38:36,  2.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0637, 'grad_norm': 0.035277824848890305, 'learning_rate': 2.2277666888445332e-05, 'epoch': 1.66}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 5500/9018 [3:00:02<2:24:11,  2.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0832, 'grad_norm': 0.05410074442625046, 'learning_rate': 1.9505433577289865e-05, 'epoch': 1.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 6000/9018 [3:17:51<1:46:22,  2.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0562, 'grad_norm': 0.01745343953371048, 'learning_rate': 1.67332002661344e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 6012/9018 [3:18:17<1:31:05,  1.82s/it]c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/precision/precision.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/recall/recall.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "                                                       \n",
            " 67%|██████▋   | 6012/9018 [3:20:05<1:31:05,  1.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3254091739654541, 'eval_accuracy': 0.9392928619079386, 'eval_f1': 0.9408706952566601, 'eval_runtime': 107.6313, 'eval_samples_per_second': 13.927, 'eval_steps_per_second': 1.747, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 6500/9018 [3:37:16<1:28:42,  2.11s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0328, 'grad_norm': 0.00961094256490469, 'learning_rate': 1.3960966954978932e-05, 'epoch': 2.16}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 7000/9018 [3:55:13<1:15:33,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0439, 'grad_norm': 0.015109258703887463, 'learning_rate': 1.1188733643823465e-05, 'epoch': 2.33}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 7500/9018 [4:08:09<34:58,  1.38s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0303, 'grad_norm': 0.009136793203651905, 'learning_rate': 8.416500332667999e-06, 'epoch': 2.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▊ | 8000/9018 [4:33:10<1:01:07,  3.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0168, 'grad_norm': 0.00585519103333354, 'learning_rate': 5.644267021512531e-06, 'epoch': 2.66}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 8500/9018 [4:57:40<26:43,  3.10s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0265, 'grad_norm': 0.006451847963035107, 'learning_rate': 2.8720337103570636e-06, 'epoch': 2.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 9000/9018 [5:26:43<00:39,  2.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0274, 'grad_norm': 0.006594103295356035, 'learning_rate': 9.98003992015968e-08, 'epoch': 2.99}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9018/9018 [5:27:24<00:00,  1.88s/it]c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/precision/precision.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/recall/recall.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "                                                     \n",
            "100%|██████████| 9018/9018 [5:29:16<00:00,  2.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5538364052772522, 'eval_accuracy': 0.9039359573048699, 'eval_f1': 0.9116564417177914, 'eval_runtime': 112.8047, 'eval_samples_per_second': 13.288, 'eval_steps_per_second': 1.667, 'epoch': 3.0}\n",
            "{'train_runtime': 19756.9422, 'train_samples_per_second': 3.651, 'train_steps_per_second': 0.456, 'train_loss': 0.10171069434642986, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9018, training_loss=0.10171069434642986, metrics={'train_runtime': 19756.9422, 'train_samples_per_second': 3.651, 'train_steps_per_second': 0.456, 'train_loss': 0.10171069434642986, 'epoch': 3.0})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 188/188 [00:57<00:00,  3.81it/s]c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/precision/precision.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/recall/recall.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "100%|██████████| 188/188 [01:03<00:00,  2.98it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5538364052772522,\n",
              " 'eval_accuracy': 0.9039359573048699,\n",
              " 'eval_f1': 0.9116564417177914,\n",
              " 'eval_runtime': 63.5333,\n",
              " 'eval_samples_per_second': 23.594,\n",
              " 'eval_steps_per_second': 2.959,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('C:/Users/DELL/Downloads/model_news\\\\tokenizer_config.json',\n",
              " 'C:/Users/DELL/Downloads/model_news\\\\special_tokens_map.json',\n",
              " 'C:/Users/DELL/Downloads/model_news\\\\vocab.json',\n",
              " 'C:/Users/DELL/Downloads/model_news\\\\merges.txt',\n",
              " 'C:/Users/DELL/Downloads/model_news\\\\added_tokens.json',\n",
              " 'C:/Users/DELL/Downloads/model_news\\\\tokenizer.json')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 指定保存模型的路径\n",
        "model_path = \"C:/Users/DELL/Downloads/model_news\"\n",
        "\n",
        "# 保存模型\n",
        "model.save_pretrained(model_path)\n",
        "\n",
        "# 同时，保存 tokenizer 到相同的路径\n",
        "tokenizer.save_pretrained(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9OCWNfaPpuzf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "100%|██████████| 188/188 [01:00<00:00,  3.57it/s]c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/precision/precision.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/recall/recall.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "100%|██████████| 188/188 [01:04<00:00,  2.91it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5538364052772522,\n",
              " 'eval_accuracy': 0.9039359573048699,\n",
              " 'eval_f1': 0.9116564417177914,\n",
              " 'eval_precision': 0.8443181818181819,\n",
              " 'eval_recall': 0.9906666666666667,\n",
              " 'eval_runtime': 64.949,\n",
              " 'eval_samples_per_second': 23.08,\n",
              " 'eval_steps_per_second': 2.895}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import Dataset, load_metric\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    AutoConfig,\n",
        ")\n",
        "model_path = \"C:/Users/DELL/Downloads/model_news\"\n",
        "\n",
        "# 加载模型\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# 加载 tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    f1 = load_metric(\"f1\")\n",
        "    precision = load_metric(\"precision\")\n",
        "    recall = load_metric(\"recall\")\n",
        "    accuracy = load_metric(\"accuracy\")\n",
        "\n",
        "    f1_score = f1.compute(predictions=predictions, references=labels, average='binary')\n",
        "    precision_score = precision.compute(predictions=predictions, references=labels, average='binary')\n",
        "    recall_score = recall.compute(predictions=predictions, references=labels, average='binary')\n",
        "    accuracy_score = accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score['accuracy'],\n",
        "        \"f1\": f1_score['f1'],\n",
        "        \"precision\": precision_score['precision'],\n",
        "        \"recall\": recall_score['recall']\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Satire\n",
            "   labels                                               text\n",
            "0       0  \\nWhen so many actors seem content to churn ou...\n",
            "   labels                                               text\n",
            "0       0  \\nThe Alberta province health minister wants t...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kiriharari/miniconda3/envs/dl/lib/python3.11/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6dbf26ea19b43c283572a41445e1449",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fecc9a186e94fc38f05cff1f492a5b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d627b9ea6cc94bfa8610bb52f04606fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probabilities: tensor([[0.9887, 0.0113]])\n",
            "Predictions: tensor([0])\n",
            "Reliable\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1cc6b42ee9e44a8aa810740cdf2a225",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probabilities: tensor([[3.0635e-05, 9.9997e-01]])\n",
            "Predictions: tensor([1])\n"
          ]
        }
      ],
      "source": [
        "test_string_satire = '''\n",
        "When so many actors seem content to churn out performances for a quick paycheck, a performer who adheres to his principles really stands out. Thats why Jeff Bridges made waves this week when he announced that from now on, he will only perform nude scenes. In an interview in this months GQ, the Big Lebowski star made it clear that he was more than ready to move on to a new phase in his career, leaving his clothed roles in the past. Ive been there and Ive done that, said Bridges, rattling off a laundry list of the films hes appeared in covered up. Now, I can finally afford to only take on roles that excite me. Right now, those are roles with nude scenes. Why waste my time with anything else? Powerful. Though he made it clear that he doesnt regret his previous non-nude roles, Jeff admitted that hed always struggled with pressure from directors and studios to stay clothed on camera. No more towels; no more bathrobes; no more carefully placed plants, he added. Even if my character isnt written as nude, any director I work with will have to figure out how to make him that way. Itll be a challenge for both of us, and one I cant wait to tackle. For their part, Jeffs fans have been nothing but supportive. Wow! Whether or not you agree with him, youve got to have respect for a Hollywood star with that much conviction. You keep doing you, Jeff!\n",
        "'''\n",
        "\n",
        "test_string_reliable = '''\n",
        "The Alberta province health minister wants to know if swine flu shots were 'inappropriately diverted' to the Calgary Flames while thousands had to stand in line for hours for the vaccine. Alberta Health Minister Ron Liepert says he doesn't know where the NHL team got the vaccine, adding that Alberta Health Services is the only supplier in the province. Team president Ken King says the club contacted the department and asked for the clinic. Health officials have begun an investigation into the special clinic, which was held for the players and their families last Friday. Liepert says the vaccine would be diverted only with the approval of the chief medical officer of health, but he doesn't know if that was the case. Alberta's opposition parties say professional ice hockey players shouldn't be getting the vaccine ahead of cancer patients and pregnant women.\n",
        "'''\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_eval_batch_size=1  # 设置为1因为我们只预测一个样本\n",
        ")\n",
        "trainer = Trainer(model=model, args=training_args)\n",
        "print(\"Satire\")\n",
        "satire_input_x = pd.DataFrame({'labels':[0], 'text': test_string_satire})\n",
        "\n",
        "reliable_input_x = pd.DataFrame({'labels':[0], 'text': test_string_reliable})\n",
        "\n",
        "satire_dataset = Dataset.from_pandas(satire_input_x)\n",
        "reliable_dataset = Dataset.from_pandas(reliable_input_x)\n",
        "\n",
        "satire_input_x = satire_dataset.map(tokenize, batched=True)\n",
        "reliable_input_x = reliable_dataset.map(tokenize, batched=True)\n",
        "\n",
        "# satire_input_x['labels'] = torch.tensor(0)\n",
        "# Check the number of tokens\n",
        "# print(\"Input IDs shape:\", satire_input_x['input_ids'].shape)  # 应显示 (1, 128) 或其他类似批处理形状\n",
        "# print(\"Input IDs shape:\", tokenized_test['input_ids'].shape) \n",
        "predictions = trainer.predict(satire_input_x)\n",
        "\n",
        "\n",
        "logits = predictions.predictions\n",
        "probs = torch.softmax(torch.tensor(logits), dim=-1)\n",
        "predictions = torch.argmax(probs, dim=-1)\n",
        "\n",
        "print(\"Probabilities:\", probs)\n",
        "print(\"Predictions:\", predictions)\n",
        "\n",
        "print(\"Reliable\")\n",
        "\n",
        "predictions = trainer.predict(reliable_input_x)\n",
        "\n",
        "\n",
        "logits = predictions.predictions\n",
        "probs = torch.softmax(torch.tensor(logits), dim=-1)\n",
        "predictions = torch.argmax(probs, dim=-1)\n",
        "\n",
        "print(\"Probabilities:\", probs)\n",
        "print(\"Predictions:\", predictions)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
